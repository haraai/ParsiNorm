<div dir='ltr' align='left'>

# pre-processing


<h1>Use total functions in predifiened order:</h1>

The file clean.py has all functions in order.
To use this function you have to make an instance from clean and then call clean_sentence method:
	
	from clean import clean
	sentence = clean.clean_sentence(sentence)

If you want to seperate sentences you have to make an instance of tokenizer class and then call sentence_tokenize function

	from Tokenizer import Tokenizer
	sentences = tokenizer.sentence_tokenize(sentences)
All in one, you can use following codes to have a preprocessing for speech processing:

	for index in range(len(sentences)):
        	for sentence in tokenizer.sentence_tokenize(sentences[index]):
                sentence = clean.clean_sentence(sentence)
		# Do every thing you want with each seprated sentence
	
<h1>Use Functions seperately:</h1>
Detect and clean URLs and emails this cleaning is by replacing symbols to how they are spelled:


	from mail_url_cleaner import mail_url_cleaner
	mail_url_cleaner = mail_url_cleaner()
	sentence = mail_url_cleaner.find_mails_clean(sentence=sentence)
	sentence = mail_url_cleaner.find_urls_clean(sentence=sentence)

Detect and covert time and dates to how they are spelled


	from date_time_to_text import date_time_to_text
	date_time_to_text = date_time_to_text()
	sentence = date_time_to_text.date_to_text(sentence=sentence)
	sentence = date_time_to_text.time_to_text(sentence=sentence)


Replace different forms of Persian and English to unique forms 

	from general_normalization import general_normalization
	general_normalization = general_normalization()
	sentence = general_normalization.alphabet_correction(sentence=sentence)
	sentence = general_normalization.english_correction(sentence=sentence)

General text normalization is used by following codes

	from general_normalization import general_normalization
	general_normalization = general_normalization()
	# To replace HTML tags with their character symbols
	sentence = general_normalization.html_correction(sentence=sentence)
	# To replace arabic symbols with how they are written completely
	sentence = general_normalization.arabic_correction(sentence=sentence)
	# To have a unique form of each puncuations
	sentence = general_normalization.punctuation_correction(sentence=sentence)
	# To replace special English symbols and characters to how they are written completely
	sentence = general_normalization.specials_chars(sentence=sentence)
	# Remove emojis
	sentence = general_normalization.remove_emojis(sentence=sentence)
	# Unique floating point with these seperators: (/,ØŒ)
	sentence = general_normalization.unique_floating_point(sentence=sentence)
	# Remove comma between numbers that are used to read numbers easily
	sentence = general_normalization.remove_comma_between_numbers(sentence=sentence)
	# Convert numbers to a unique Persian unicode
	sentence = general_normalization.number_correction(sentence=sentence)
	# Remove characters and symbols that are not in list of acceptable characters
	sentence = general_normalization.remove_not_desired_chars(sentence=sentence)
	# Remove punctuations that are repeated except for dot(.)
	sentence = general_normalization.remove_repeated_punctuation(sentence=sentence)

Detect and replace telephone numbers with how they are pronounced

	from telephone_number import telephone_number
	telephone_number = telephone_number()
	sentence = telephone_number.find_phones_replace(sentence=sentence)

Detect and Replace English and Persian abbrevation with how they are read

	from abbreviation import abbreviation
	abbreviation = abbreviation()
	sentence = abbreviation.replace_date_abbreviation(sentence=sentence)
	sentence = abbreviation.replace_persian_label_abbreviation(sentence=sentence)
	sentence = abbreviation.replace_law_abbreviation(sentence=sentence)
	sentence = abbreviation.replace_book_abbreviation(sentence=sentence)
	sentence = abbreviation.replace_other_abbreviation(sentence=sentence)
	sentence = abbreviation.replace_English_abbrevations(sentence=sentence)

Speech processing normalization. This class replace non standard characters and symbols to how they are spelled
	
	from TTS_normalization import TTS_normalization
	TTS_normalization = TTS_normalization()
	sentence = TTS_normalization.math_correction(sentence=sentence)
	sentence = TTS_normalization.replace_currency(sentence=sentence)

Replace numbers and special numbers such as floating points, national code, card number, sheba to how they are read 

	from special_numbers import special_numbers
	special_numbers = special_numbers()
	sentence = special_numbers.convert_numbers_to_text(sentence=sentence)
	sentence = special_numbers.replace_national_code(sentence=sentence)
	sentence = special_numbers.replace_card_number(sentence=sentence)
	sentence = special_numbers.replace_shaba(sentence=sentence)

Remove unnecessary sentences

	from data_cleaning import data_cleaning
	data_cleaning = data_cleaning()
	sentence = data_cleaning.remove_just_url(sentence=sentence)
	sentence, isEnglish = data_cleaning.remove_english_sentence(sentence=sentence)
	sentence = data_cleaning.remove_html_tags(sentence=sentence)
	sentence = self.data_cleaning.remove_article_code(sentence=sentence)


<h1>Examples</h1>

```python
>>> from mail_url_cleaner import mail_url_cleaner
>>> mail_url_cleaner = mail_url_cleaner()
>>> mail_url_cleaner.find_mails_clean(sentence="info@hara.ai")
info at hara dot ai

>>> mail_url_cleaner.find_urls_clean(sentence="https://hara.ai/#services")
https do noghte slash slash hara dot ai

>>> from date_time_to_text import date_time_to_text
>>> date_time_to_text = date_time_to_text()
>>> date_time_to_text.date_to_text(sentence='2021/10/27')
Ø¨ÛŒØ³Øª Ùˆ Ù‡ÙØªÙ… Ø§Ú©ØªØ¨Ø± Ø³Ø§Ù„ Ø¯Ùˆ Ù‡Ø²Ø§Ø± Ùˆ Ø¨ÛŒØ³Øª Ùˆ ÛŒÚ©

>>> date_time_to_text.time_to_text(sentence='22:57:11')
Ø¨ÛŒØ³Øª Ùˆ Ø¯Ùˆ Ùˆ Ù¾Ù†Ø¬Ø§Ù‡ Ùˆ Ù‡ÙØª Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ  ÛŒØ§Ø²Ø¯Ù‡ Ø«Ø§Ù†ÛŒÙ‡

>>> from general_normalization import general_normalization
>>> general_normalization = general_normalization()
>>> general_normalization.alphabet_correction(sentence='ï»™ï¯˜Ý™Ý¤ï®®')
Ú©ÙˆØ¯Ú©ÛŒ

>>> general_normalization.english_correction(sentence='naÃ¯ve')
naive

>>> general_normalization.html_correction(sentence='&quot;')
"

>>> general_normalization.arabic_correction(sentence='ï·º')
ØµÙ„ÛŒ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÛŒÙ‡ Ùˆ Ø³Ù„Ù…

>>> general_normalization.punctuation_correction(sentence="â€¦")
...

>>> general_normalization.specials_chars(sentence="â„¡")
TEL

>>> general_normalization.remove_emojis(sentence='ðŸ˜Š')


>>> general_normalization.unique_floating_point(sentence='1ØŒ2')
Û±.Û²

>>> general_normalization.remove_comma_between_numbers(sentence='1Ù¬234')
Û±Û²Û³Û´

>>> general_normalization.number_correction(sentence="â‘¤")
Ûµ

>>> general_normalization.remove_not_desired_chars(sentence="^ Hi ~")
  Hi  

>>> general_normalization.remove_repeated_punctuation(sentence="!!!!!")
!

>>> from telephone_number import telephone_number
>>> telephone_number = telephone_number()
>>> telephone_number.find_phones_replace(sentence='ØªÙ„ÙÙ† Û°Û²Û±Û³Û³Û´ÛµÛ¶Û·Û¸Û¸')
ØªÙ„ÙÙ†   ØµÙØ±  Ø¨ÛŒØ³Øª Ùˆ ÛŒÚ© Ø³ÛŒ Ùˆ Ø³Ù‡ Ú†Ù‡Ù„ Ùˆ Ù¾Ù†Ø¬ Ø´ØµØª Ùˆ Ù‡ÙØª Ù‡Ø´ØªØ§Ø¯ Ùˆ Ù‡Ø´Øª

>>> from abbreviation import abbreviation
>>> abbreviation = abbreviation()
>>> abbreviation.replace_date_abbreviation(sentence=".Ø¯Ø± Ø³Ø§Ù„ 1400 Ù‡.Ø´")
Ø¯Ø± Ø³Ø§Ù„ 1400 Ù‡Ø¬Ø±ÛŒ Ø´Ù…Ø³ÛŒ

>>> abbreviation.replace_persian_label_abbreviation(sentence='Ø§Ù…Ø§Ù… Ø²Ù…Ø§Ù† (Ø¹Ø¬)')
Ø§Ù…Ø§Ù… Ø²Ù…Ø§Ù†  Ø¹Ø¬Ù„ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„ÛŒ ÙØ±Ø¬Ù‡ Ø§Ù„Ø´Ø±ÛŒÙ 

>>> abbreviation.replace_law_abbreviation(sentence='Ø¯Ø± Ù‚.Ø§ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª')
Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† Ø§Ø³Ø§Ø³ÛŒ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª

>>> abbreviation.replace_book_abbreviation(sentence='Ø¨Ù‡ Ú©ØªØ§Ø¨ Ø²ÛŒØ± Ø±.Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯')
Ø¨Ù‡ Ú©ØªØ§Ø¨ Ø²ÛŒØ± Ø±Ø¬ÙˆØ¹ Ú©Ù†ÛŒØ¯ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯

>>> abbreviation.replace_other_abbreviation(sentence='Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† Ø¬.Ø§ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª')
Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ† Ø¬Ù…Ù‡ÙˆØ±ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª

>>> abbreviation.replace_English_abbrevations(sentence='U.S.A')
ÛŒÙˆ Ø§Ø³ Ø¢

>>> from TTS_normalization import TTS_normalization
>>> TTS_normalization = TTS_normalization()
>>> TTS_normalization.math_correction(sentence='â…ž')
Ù‡ÙØª Ù‡Ø´ØªÙ…

>>> TTS_normalization.replace_currency(sentence='Û³Û³$')
Û³Û³ Ø¯Ù„Ø§Ø±

>>> from special_numbers import special_numbers
>>> special_numbers = special_numbers()
>>> special_numbers.convert_numbers_to_text(sentence='122')
 ØµØ¯ Ùˆ Ø¨ÛŒØ³Øª Ùˆ Ø¯Ùˆ

>>> special_numbers.replace_national_code(sentence='0499370899')
ØµÙØ±  Ú†Ù‡Ø§Ø±   Ù†Ù‡ØµØ¯ Ùˆ Ù†ÙˆØ¯ Ùˆ Ø³Ù‡   Ù‡ÙØªØ§Ø¯   Ù‡Ø´ØªØµØ¯ Ùˆ Ù†ÙˆØ¯ Ùˆ Ù†Ù‡

>>> special_numbers.replace_card_number(sentence='6037701689095443')
Ø´ØµØª   Ø³ÛŒ Ùˆ Ù‡ÙØª   Ù‡ÙØªØ§Ø¯   Ø´Ø§Ù†Ø²Ø¯Ù‡   Ù‡Ø´ØªØ§Ø¯ Ùˆ Ù†Ù‡   ØµÙØ±  Ù†Ù‡   Ù¾Ù†Ø¬Ø§Ù‡ Ùˆ Ú†Ù‡Ø§Ø±   Ú†Ù‡Ù„ Ùˆ Ø³Ù‡

>>>special_numbers.replace_shaba(sentence='IR820540102680020817909002')
 Ø¢ÛŒ Ø¢Ø±   Ù‡Ø´ØªØ§Ø¯ Ùˆ Ø¯Ùˆ   ØµÙØ±  Ù¾Ù†Ø¬   Ú†Ù‡Ù„   Ø¯Ù‡   Ø¨ÛŒØ³Øª Ùˆ Ø´Ø´   Ù‡Ø´ØªØ§Ø¯   ØµÙØ±  Ø¯Ùˆ   ØµÙØ±  Ù‡Ø´Øª   Ù‡ÙØ¯Ù‡   Ù†ÙˆØ¯   Ù†ÙˆØ¯   ØµÙØ±  Ø¯Ùˆ 

>>> from Tokenizer import Tokenizer
>>> tokenizer = Tokenizer()
>>> tokenizer.sentence_tokenize('.Ø§ÛŒÙ† Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª. Ø¨Ø§ÛŒØ¯ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø§Ù†Ø¬Ø§Ù… Ú¯ÛŒØ±Ø¯. Ø¯Ø±Ø³Øª Ø§Ø³Øª') 
['Ø§ÛŒÙ† Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª .', ' Ø¨Ø§ÛŒØ¯ Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø§Ù†Ø¬Ø§Ù… Ú¯ÛŒØ±Ø¯ .', ' Ø¯Ø±Ø³Øª Ø§Ø³Øª .']

```

<h1>To Do:</h1>
<ul>
  <li>Slash "/" in different contexts </li>
  <li>"+" in different contexts </li>
</ul>  

</div>
